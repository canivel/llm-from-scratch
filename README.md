# LLM from 0 to RLVR with GRPO

Personal implementations and notes while working through LLM-related books. Each folder contains code written as I follow along with the material.

## Books

### Book 1: Build a Large Language Model (From Scratch)
**Author:** Sebastian Raschka
**Link:** [Manning](https://www.manning.com/books/build-a-large-language-model-from-scratch)

Covers the fundamentals of building a GPT-style LLM from the ground up.

### Book 2: Build a DeepSeek Model (From Scratch)
**Author:** Sebastian Raschka
**Link:** [Manning](https://www.manning.com/books/build-a-deepseek-model-from-scratch)

Explores modern LLM architectures including MoE (Mixture of Experts) and Multi-head Latent Attention.

### Book 3: The RLHF Book
**Author:** Sebastian Raschka
**Link:** [Manning](https://www.manning.com/books/the-rlhf-book)

Covers alignment techniques: RLHF, DPO, and other preference optimization methods.

## Structure

```
book1/   # LLM from scratch implementations
book2/   # DeepSeek model implementations
book3/   # RLHF and alignment code
```

## Progress

- [ ] Book 1: Build a Large Language Model (in progress) eta 2 weeks
- [ ] Book 2: Build a DeepSeek Model
- [ ] Book 3: The RLHF Book
